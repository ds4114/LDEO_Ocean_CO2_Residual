{
 "cells": [
  {
   "cell_type": "raw",
   "id": "310f7d18",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e2fca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import datetime\n",
    "import numpy.ma as ma\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b10e2558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This file contains configuration details like API keys and passwords\n",
    "global_vars = yaml.safe_load(open('../config.yml', 'r') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5b5c09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: ESMFMKFILE=/srv/conda/envs/notebook/lib/esmf.mk\n"
     ]
    }
   ],
   "source": [
    "#There are some issues with xesmf installation so we need to point to a file required for the package. See README.md for details.\n",
    "ESMFMKFILE = global_vars['ESMFMKFILE']\n",
    "%env ESMFMKFILE $ESMFMKFILE  \n",
    "import xesmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53354db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This has custom functions - several but the fCO2_to_pCO2 function is key\n",
    "%run ./00_custom_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01d540c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data will be processed in: gs://leap-persistent/galenmckinley/online_data/\n",
      "Files will be outputed as: .zarr\n"
     ]
    }
   ],
   "source": [
    "# To ingest the raw data downloaded in the previous script, we need to point to the location of the downloads\n",
    "# Data will be read at this location in folders such as root/SST/originals/ and root/SSS/orginals/\n",
    "# Processed data will be saved to folders such as root/SST/processed/ \n",
    "# Note that data file names within these folders have been hardcoded in each section below\n",
    "data_folder_root = global_vars['download_folder']\n",
    "print(f'Data will be processed in: {data_folder_root}')\n",
    "\n",
    "#This variable sets the output file type. \n",
    "#When using cloud storage, it is recommended to use ARCO (Analysis-Ready Cloud-Optimized) formats like Zarr over NetCDF\n",
    "output_file_type = '.zarr' if data_folder_root[0:5] == 'gs://' else '.nc'\n",
    "print(f'Files will be outputed as: {output_file_type}')\n",
    "\n",
    "# The following two variables are used to slice the data to desired time frames for consistency or to backfill historical data with averages. No changes required.\n",
    "# Given the time range limitiations of the raw data, this primarily affects MLD (1 year repeated) and CHL (linear interpoloation). \n",
    "# For other data like SLP, this limits the real-time (experimental) data from recent months\n",
    "# Note that all input files should have data in at least this time frame\n",
    "processed_start_yearmonth = '1982-01'  \n",
    "processed_end_yearmonth = '2023-12'   \n",
    "\n",
    "figsizew, figsizeh = 6, 3  #figure size for maps (width/height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2f5217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create desired resolution and time frame\n",
    "ylat = xr.DataArray(data=[x+.5 for x in range(-90, 90, 1)], dims=['ylat'], coords=dict( ylat=(['ylat'],[x+.5 for x in range(-90, 90, 1)]) ),)\n",
    "xlon = xr.DataArray(data=[x+.5 for x in range(-180,180,1)], dims=['xlon'], coords=dict( xlon=(['xlon'],[x+.5 for x in range(-180,180,1)]) ),)\n",
    "ttime = pd.date_range(start=str(processed_start_yearmonth), end=str(processed_end_yearmonth),freq='MS') + np.timedelta64(14, 'D') #time should be monthly on the middle of the month\n",
    "        #note that the time doesnt affect regridding but we do use this time to overwrite the monthly dates so its consistent\n",
    "\n",
    "ideal_grid = xr.Dataset({'time':(['time'],ttime.values), 'latitude':(['latitude'],ylat.values),'longitude':(['longitude'],xlon.values)}) #must be named this way for old XESFM versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66bd3509-c690-40c8-8c46-33ba6775c8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "504"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttime.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a566072",
   "metadata": {},
   "source": [
    "## Temperature (SST)\n",
    "#### NOAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82501bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "## UPDATE HERE WHEN NEW DATA RETRIEVED ##\n",
    "########################################\n",
    "sst = xr_open_dataset_custom(data_folder_root+r'SST/originals/SST_NOAA_OI-V2-HighRes_198109-202402.nc')  \n",
    "        #previously SST_NOAA_OI-V2-HighRes_198109-202308.nc')  \n",
    "        #previously SST_NOAA_OI-V2-HighRes_198109-202306.nc\n",
    "#sst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802025fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sst_filtered = sst.sel(time=slice(str(processed_start_yearmonth),str(processed_end_yearmonth))) #already monthly so select desired years\n",
    "sst_regridder = xesmf.Regridder(sst_filtered, ideal_grid, 'conservative', periodic=True)  #see notes above on why conservative over bilinear\n",
    "sst_out = sst_regridder(sst_filtered.chunk(-1) , keep_attrs=True)\n",
    "#sst_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f381e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_out = sst_out.rename({'latitude': 'ylat','longitude': 'xlon'}) #rename to be consistent with prior work\n",
    "sst_out = sst_out.assign_coords(time=ttime) #overwrite time dimension to be midmonth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00042c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_xarray_with_date(sst_out, data_folder_root+'SST/processed/', 'SST_NOAA_OI-V2-1x1', output_file_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0850a3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(figsizew,figsizeh))\n",
    "plt.contourf(ideal_grid.longitude,ideal_grid.latitude,sst_out.sst.sel(time='2022-06-15')) #just choosing latest time slice\n",
    "plt.title('NOAA SST (latest month)'); plt.xlabel('Lon'); plt.ylabel('Lat')\n",
    "plt.colorbar().set_label('deg C');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c248459-1690-4054-967c-befe955a6b70",
   "metadata": {},
   "source": [
    "#### ECMWF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa2e33f0-b5e0-4ee6-a46f-bf67f7844da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encountered an error - trying with gs://leap-persistent/galenmckinley/online_data/SST/originals/SST_ECMWF_ERA5-monthly-reanalysis-SST_*.zarr\n",
      "Success.\n"
     ]
    }
   ],
   "source": [
    "#sst_era5 = xr.open_mfdataset(data_folder_root+r'SST/originals/SST_ECMWF_ERA5-monthly-reanalysis-SST_*.nc') \n",
    "sst_era5 = xr_open_mfdataset_custom(data_folder_root+r'SST/originals/SST_ECMWF_ERA5-monthly-reanalysis-SST_*.nc') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0adc6a0-d2d6-41fe-8e3a-e9e87f197d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Regrid sst_era5\n",
    "sst_era5_highres = sst_era5.sel(expver=1) #previously required sst_era5.sel(expver=1) to remove the experimental/recent data but dimension is not included now\n",
    "sst_era5_highres = sst_era5_highres.sst - 273.15  #Also convert deg K to deg C.\n",
    "    #Note the expver variable in era5 indicates new experimental data: #https://confluence.ecmwf.int/pages/viewpage.action?pageId=173385064\n",
    "sst_era5_highres = sst_era5_highres.sel(time=slice(str(processed_start_yearmonth),str(processed_end_yearmonth))) #already monthly so select desired years\n",
    "sst_era5_highres = xr.Dataset({'sst_era5':(['time','latitude','longitude'],sst_era5_highres.data),'time':(['time'],sst_era5_highres.time.data),'latitude':(['latitude'],sst_era5_highres.latitude.data),'longitude':(['longitude'],sst_era5_highres.longitude.data)})\n",
    "sst_era5_highres_regridder = xesmf.Regridder(sst_era5_highres, ideal_grid, 'bilinear', periodic=True) #See note above about bilinear vs conservative\n",
    "sst_era5_out = sst_era5_highres_regridder(sst_era5_highres, keep_attrs=False)\n",
    "#sst_era5_out = sst_era5_highres_regridder(sst_era5_highres.chunk(-1), keep_attrs=False)\n",
    "#sst_era5_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321dc7fe-807b-47e6-b8a7-4d4170b1789f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_era5_out = sst_era5_out.rename({'latitude': 'ylat','longitude': 'xlon'}) #rename to be consistent with prior work\n",
    "sst_era5_out = sst_era5_out.assign_coords(time=ttime) #overwrite time dimension to be midmonth\n",
    "sst_era5_out.sst_era5.attrs['units'] = 'deg C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab941318-b8e3-499a-a9ba-d1b52f73d261",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_xarray_with_date(sst_era5_out, data_folder_root+'SST/processed/', 'SST_ECMWF_ERA5-monthly-reanalysis-1x1-SST', output_file_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b475ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(figsizew,figsizeh))\n",
    "plt.contourf(ideal_grid.longitude,ideal_grid.latitude,sst_era5_out.sst_era5.sel(time='2022-06-15').data) #just choosing one time slice\n",
    "plt.title('ERA5 SST (last summer)'); plt.xlabel('Lon'); plt.ylabel('Lat')\n",
    "plt.colorbar().set_label('deg C');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2b2645-2b90-4c31-bc8c-12ed3e0c4827",
   "metadata": {},
   "source": [
    "#### JRA55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4662535-becb-4c7f-b7ec-d6a039c6ef25",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_jra55 = xr_open_mfdataset_custom(data_folder_root+r'SST/originals/SST_JMA_JRA55-do-daily-reanalysis-SST_*.nc')\n",
    "#There is a lot of metadata in these files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e660ad2-b117-4523-982e-90768b584c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data is on a dialy basis so we need to average to get a monthly SST\n",
    "sst_jra55_monthly = sst_jra55.tos.resample({'time':'1m'}).mean()\n",
    "    #np.array(test.sel(time='2018-01-31',lat=0.5,lon=.5)) #28.461128\n",
    "\n",
    "#Next, regrid\n",
    "sst_jra55_monthly = sst_jra55_monthly.sel(time=slice(str(processed_start_yearmonth),str(processed_end_yearmonth))) #to select desired years\n",
    "sst_jra55_monthly = sst_jra55_monthly.to_dataset(name='sst_jra55')\n",
    "sst_jra55_monthly_regridder = xesmf.Regridder(sst_jra55_monthly, ideal_grid, 'bilinear', periodic=True) #See note above about bilinear vs conservative\n",
    "sst_jra55_out = sst_jra55_monthly_regridder(sst_jra55_monthly.chunk(-1), keep_attrs=False)\n",
    "#sst_jra55_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafaa45d-d834-4461-a6f2-421c17cc25d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_jra55_out = sst_jra55_out.rename({'latitude': 'ylat','longitude': 'xlon'}) #rename to be consistent with prior work\n",
    "sst_jra55_out = sst_jra55_out.transpose('time','ylat','xlon')\n",
    "sst_jra55_out = sst_jra55_out.assign_coords(time=ttime) #overwrite time dimension to be midmonth\n",
    "sst_jra55_out.attrs['units'] = 'deg C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64764872-8b95-437f-80f1-eb369d3dfb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_xarray_with_date(sst_jra55_out, data_folder_root+'SST/processed/', 'SST_JMA_JRA55-do-monthly-reanalysis-SST', output_file_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffa9fe5-91be-4e9e-896b-a06f245feb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(figsizew,figsizeh))\n",
    "plt.contourf(ideal_grid.longitude,ideal_grid.latitude,sst_jra55_out.sst_jra55.sel(time='2022-06-15').data) #just choosing one time slice\n",
    "plt.title('JRA55 SST (last summer)'); plt.xlabel('Lon'); plt.ylabel('Lat')\n",
    "plt.colorbar().set_label('deg C');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6e97ff-be78-4394-9f5e-d7a2f5b6599b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78894572",
   "metadata": {},
   "source": [
    "## Salinity (SSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d469c531",
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = xr_open_mfdataset_custom(data_folder_root+'SSS/originals/EN.4.2.2.f.analysis.g10.*.nc') \n",
    "#sss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb0879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#effectively ignore the depth dimension because we dont need it\n",
    "sss_nodepth = xr.Dataset({'sss':(['time','lat','lon'],sss.salinity[:,0,:,:].values),'time':(['time'],sss.time.data),'lat':(['lat'],sss.lat.data),'lon':(['lon'],sss.lon.data)})\n",
    "#Note this removes attributes from SSS raw data so we lose some metadata but this is OK for this analysis\n",
    "sss_filtered = sss_nodepth.sel(time=slice(str(processed_start_yearmonth),str(processed_end_yearmonth))) #filter years\n",
    "\n",
    "#Regrid lat/lon\n",
    "sss_regridder = xesmf.Regridder(sss_filtered, ideal_grid, 'bilinear', periodic=True)  #data is already 1x1 but we want to shift coordinates\n",
    "sss_out = sss_regridder(sss_filtered.chunk(-1), keep_attrs=True)\n",
    "#sss_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3065324b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sss_out = sss_out.rename({'latitude': 'ylat','longitude': 'xlon'}) #rename to be consistent with prior work\n",
    "sss_out = sss_out.assign_coords(time=ttime) #overwrite time dimension to be midmonth\n",
    "#sss_out = sss_out.assign_coords(time=ttime[:-1]) #you can use this line if SSS hasnt updated and we are missing the last month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4064d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_xarray_with_date(sss_out, data_folder_root+'SSS/processed/', 'SSS_Met-Office-Hadley-Centre_EN422f-g10-analyses', output_file_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4021d932",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(figsizew,figsizeh))\n",
    "plt.contourf(ideal_grid.longitude,ideal_grid.latitude,sss_out.sss[-1,:,:]) #just choosing latest time slice\n",
    "plt.title('SSS (latest month)'); plt.xlabel('Lon'); plt.ylabel('Lat')\n",
    "plt.colorbar().set_label('g/kg');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c248c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43e01a86",
   "metadata": {},
   "source": [
    "## Mixed Layer Depth (MLD)\n",
    "#### deBoyer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac7738c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mld_ds = xr_open_dataset_custom(data_folder_root+r'MLD/originals/MLD_IFREMER-deBoyer_DT02-c1m_2008.nc', decode_times=False) # had to remove extra '/'\n",
    "mld = mld_ds.mld  #just need the mld variable. Data is 2x2 resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb3d78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are strange anomalies in the raw data which we are going to filter out\n",
    "mld_filtered = mld.where(((mld>0)&(mld<5000))) \n",
    "\n",
    "#TODO - Document these next commands\n",
    "mld_filtered2 = np.where(np.isnan(mld_filtered), ma.array(mld_filtered, mask=np.isnan(mld_filtered)).mean(axis=2)[:,:,np.newaxis], mld_filtered)\n",
    "mld_filtered2 = np.where(mld_filtered2==0,np.nan,mld_filtered2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7ce20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mld_in = xr.Dataset({'mld':(['time','lat','lon'],mld_filtered2),'time':(['time'],range(0,12)),'lat':(['lat'],mld_filtered.lat.values),'lon':(['lon'],mld_filtered.lon.values)})\n",
    "\n",
    "mld_regridder = xesmf.Regridder(mld_in, ideal_grid, 'bilinear', periodic=True) \n",
    "mld_out = mld_regridder(mld_filtered2, keep_attrs=True) # mld_out = mld_regridder(mld_filtered2.chunk(-1), keep_attrs=True)\n",
    "mld_out = np.where(np.isnan(mld_out),0,mld_out)\n",
    "#mld_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15676287",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we now have 12 months of MLD data, let's replicate for the desired time frame so merging is easier later\n",
    "mld_out_full = np.empty(shape=(len(ttime),180,360)) \n",
    "#now fill array with averaged year\n",
    "for i, m in enumerate(ttime): \n",
    "    mld_out_full[i,:,:] = mld_out[m.month-1,:,:]\n",
    "#mld_out_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0987d611",
   "metadata": {},
   "outputs": [],
   "source": [
    "mld_out_full_xr = xr.Dataset({'mld':([\"time\",\"ylat\",\"xlon\"],mld_out_full.data)},\n",
    "                        coords={'time': (['time'],ttime.values),'ylat':(['ylat'],ideal_grid.latitude.data),'xlon':(['xlon'],ideal_grid.longitude.data)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8893f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_xarray_with_date(mld_out_full_xr, data_folder_root+'MLD/processed/', 'MLD_IFREMER-deBoyer_DT02-c1m-1x1', output_file_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9d23ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "levelspace = np.linspace(0,560,11)\n",
    "fig,ax = plt.subplots(1,2,figsize=(figsizew*2, figsizeh))\n",
    "x0=ax[0].contourf(ideal_grid.longitude,ideal_grid.latitude,mld_out_full_xr.mld[6,:,:], levels=levelspace) #just choosing a summer month (July)\n",
    "x1=ax[1].contourf(ideal_grid.longitude,ideal_grid.latitude,mld_out_full_xr.mld[0,:,:], levels=levelspace) #just choosing a winter month (Jan)\n",
    "ax[0].set_title(\"MLD July\"); ax[1].set_title(\"MLD Jan\");\n",
    "ax[0].set_xlabel('Lon'); ax[0].set_ylabel('Lat');\n",
    "ax[1].set_xlabel('Lon'); ax[1].set_ylabel('Lat');\n",
    "plt.colorbar(x0, ax=ax[0]).set_label('meters');\n",
    "plt.colorbar(x1, ax=ax[1]).set_label('meters');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240cd27a-80e9-422a-9aff-a9f144c991a3",
   "metadata": {},
   "source": [
    "#### UCSD / Argo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1fad03-5ae8-44aa-988e-9da1013ca110",
   "metadata": {},
   "outputs": [],
   "source": [
    "mld_argo = xr_open_dataset_custom(data_folder_root + r'MLD/originals/MLD_UCSD-Argo_mixedlayers-monthlyclim_2022.nc')\n",
    "mld_argo = mld_argo.transpose('iMONTH','iLAT','iLON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe965a9f-d1fe-4716-8cd3-3abf8f90f5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mld_argo_filled = mld_argo.mld_dt_mean.fillna(0)  #replace nan with 0 to be consistent with prior work\n",
    "\n",
    "#Note: The coordinates for this source netCDF are assumed aligned to the same 1x1 grid\n",
    "    #So regridding not required \n",
    "    #we have 12 months of MLD data, let's replicate for the desired time frame so merging is easier later\n",
    "mld_argo_out_full = np.empty(shape=(len(ttime),180,360)) \n",
    "for i, m in enumerate(ttime): \n",
    "    mld_argo_out_full[i,:,:] = mld_argo_filled[m.month-1,:,:]\n",
    "mld_argo_out_full_xr = xr.Dataset({'mld_argo':([\"time\",\"ylat\",\"xlon\"],mld_argo_out_full.data)},\n",
    "                        coords={'time': (['time'],ttime.values),'ylat':(['ylat'],ideal_grid.latitude.data),'xlon':(['xlon'],ideal_grid.longitude.data)})\n",
    "#mld_out_full_xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3ecadc-44a0-40bd-b087-74a5467d91ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_xarray_with_date(mld_argo_out_full_xr, data_folder_root+'MLD/processed/', 'MLD_UCSD-Argo_MLD-dt-mean-1x1', output_file_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459e3477-08a7-4c82-93dd-1ad2a655286a",
   "metadata": {},
   "outputs": [],
   "source": [
    "levelspace = np.linspace(0,640,11)\n",
    "fig,ax = plt.subplots(1,2,figsize=(figsizew*2, figsizeh))\n",
    "x0=ax[0].contourf(ideal_grid.longitude,ideal_grid.latitude,mld_argo_out_full_xr.mld_argo[6,:,:], levels=levelspace) #just choosing a summer month (July)\n",
    "x1=ax[1].contourf(ideal_grid.longitude,ideal_grid.latitude,mld_argo_out_full_xr.mld_argo[0,:,:], levels=levelspace) #just choosing a winter month (Jan)\n",
    "ax[0].set_title(\"MLD July\"); ax[1].set_title(\"MLD Jan\");\n",
    "ax[0].set_xlabel('Lon'); ax[0].set_ylabel('Lat');\n",
    "ax[1].set_xlabel('Lon'); ax[1].set_ylabel('Lat');\n",
    "plt.colorbar(x0, ax=ax[0]).set_label('meters');\n",
    "plt.colorbar(x1, ax=ax[1]).set_label('meters');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494de337-2623-41d4-a6f2-5c37f2e77935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aeaa45cc",
   "metadata": {},
   "source": [
    "## Chlorophyll (CHL)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d88b632",
   "metadata": {},
   "source": [
    "#According to the Bennington paper, we fill the missing winter months at the poles by linearly interpolating between the last month observed prior to the winter and the first month observed after winter. Also, for prior to 1998, we use the climatology of Chlorophyll-a calculated from observations we do have.\n",
    "\n",
    "#General Process: \n",
    "#0) combine data and filter time to relevant period\n",
    "#1) group by month to get an 'average' year\n",
    "#2) loop that year into two years so that we can linearly interpolate without boundary issues in Jan/Dec. Only need the middle 12 months.\n",
    "#3) fill in 1982 to 1997 with that averaged year\n",
    "#4) combine with the 1998+ data to get full set and interpolate on full set again to fill missing\n",
    "#5) fill remaining missing with the averaged year \n",
    "#6) regrid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd34db5-4a7c-4442-a65e-209927b09b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0) First acquire a full list of relevant files. \n",
    "files = glob.glob(data_folder_root+'CHL/originals/*.nc')\n",
    "if data_folder_root[0:5] == 'gs://': # need '=='\n",
    "    import gcsfs\n",
    "    fs = gcsfs.GCSFileSystem()\n",
    "    files = fs.glob(data_folder_root+'CHL/originals/*.zarr')\n",
    "    files = ['gs://'+f for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee305941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0 continued) Then combine data and filter for the relevant time period. Because CHL data does not have a time dimension in raw data, we need to add it to each file before/during concatenation \n",
    "chl = xr.concat([add_time_to_globcolour(fl) for fl in files], dim='time')\n",
    "chl\n",
    "chl_filter = chl.sortby('time').sel(time=slice(str(processed_start_yearmonth),str(processed_end_yearmonth))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56cae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) Next we group by month to get and 'average' year\n",
    "    #Note that we are using data from the desired time frame to calculate an average year. This means past data will change when more years are added.\n",
    "chl_avg_by_month = chl_filter.CHL1_mean.groupby(\"time.month\").mean(\"time\")  #only need the mean variable\n",
    "#2) Then we loop that year (duplicate) into two years so that we can linearly interpolate without boundary issues in Jan/Dec. We will only need the middle 12 months.\n",
    "chl_looped = np.empty(shape=(24,180,360))  #2 years of data.\n",
    "chl_looped[0:6,:,:] = chl_avg_by_month[6:12,:,:]  #set start of loop to be July to Dec. Winter at the north pole is at the end/start of the year\n",
    "chl_looped[6:18,:,:] = chl_avg_by_month\n",
    "chl_looped[18:24,:,:] = chl_avg_by_month[0:6,:,:]  #set end of loop to be Jan to Jun\n",
    "chl_looped_xr = xr.Dataset({'chl':(['time','lat','lon'],chl_looped)},\n",
    "                       coords={'time':(['time'],range(0,24)),'lat':(['lat'],chl_avg_by_month.lat.values),'lon':(['lon'],chl_avg_by_month.lon.values)})\n",
    "chl_looped_interpolated = chl_looped_xr.chl.interpolate_na(dim='time',method='linear',limit=7)\n",
    "chl_avg_year = chl_looped_interpolated[6:18,:,:]   #the full year we interpolated is in the middle. Starts in Jan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f7c946",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3) Now we fill in 1982 to 1997 with that averaged year\n",
    "earliest_chl_date = chl.time.min().data.astype('datetime64[s]').item()\n",
    "chl_missing_years = np.empty(shape=(sum(ttime < earliest_chl_date),180,360))  #create empty array of size equal to number of missing months\n",
    "chl_missing_years = xr.DataArray(chl_missing_years, coords=dict(time=ttime[ttime < earliest_chl_date], lat=chl_avg_year.lat, lon=chl_avg_year.lon), dims=[\"time\", \"lat\", \"lon\"]) #make it an xr\n",
    "chl_avg_fullset = np.empty(shape=(len(ttime),180,360))   #this is just the average which we will use later to fill missing holes from interpolation\n",
    "#now fill array with averaged year\n",
    "for i, m in enumerate(ttime):   #loop through months between start and end date\n",
    "    chl_avg_fullset[i,:,:] = chl_avg_year[m.month-1,:,:]\n",
    "    if m < earliest_chl_date: \n",
    "        chl_missing_years[i,:,:] = chl_avg_year[m.month-1,:,:]\n",
    "#chl_missing_years.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdabcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4) Next, combine the pre-1997 set with the 1998+ data to get a full set. Then interpolate on full set again to fill missing points.\n",
    "chl_filter_with_missing = xr.concat([chl_missing_years, chl_filter.CHL1_mean], dim='time')\n",
    "chl_filter_interpolate = chl_filter_with_missing.chunk(-1).interpolate_na(dim='time',method='linear',limit=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335e8dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5) For any remaining missing values that could not be interpolated, we fill with the averaged climatology\n",
    "chl_filter_interpolate_xr = xr.Dataset({'chl':(['time','lat','lon'],chl_filter_interpolate.data)  #make as a dataset so we can use fillna\n",
    "                                       #,'clim_repeat':(['time','lat','lon'], chl_avg_fullset)    #This field was used in a prior version of code but is not required\n",
    "                            }, coords={'time':(['time'],chl_filter_interpolate.time.values),'lat':(['lat'],chl_filter_interpolate.lat.values),'lon':(['lon'],chl_filter_interpolate.lon.values)})\n",
    "chl_filter_final = chl_filter_interpolate_xr.fillna(chl_avg_fullset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f71fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6) Regrid \n",
    "chl_regridder = xesmf.Regridder(chl_filter_final, ideal_grid, 'bilinear', periodic=True)\n",
    "chl_out = chl_regridder(chl_filter_final.chunk(-1), keep_attrs=True)\n",
    "chl_out = chl_out.rename({'latitude': 'ylat','longitude': 'xlon'}) \n",
    "chl_out['chl'].attrs['description'] = \"Interpolated linearly between months, climatology prior to 1998-01\"  \n",
    "chl_out['chl'].attrs['units'] = \"mg / m3\"\n",
    "#chl_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d79a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_xarray_with_date(chl_out, data_folder_root+'CHL/processed/', 'CHL_ARI-ST-GlobColour_L3m-GLOB-100-merged-GSM-CHL1', output_file_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417eb4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(figsizew,figsizeh))\n",
    "plt.contourf(ideal_grid.longitude,ideal_grid.latitude,np.ma.log10(chl_out.chl[12*20+6,:,:]))  #just one summer month; log scale to make more readable\n",
    "plt.title('CHL (July)'); plt.xlabel('Lon'); plt.ylabel('Lat')\n",
    "plt.colorbar().set_label('mg/m3 log scale');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53123e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8da4ecf2",
   "metadata": {},
   "source": [
    "## Sea Level Pressure (SLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13a8c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mslp = xr_open_mfdataset_custom(data_folder_root+r'SLP/originals/SLP_ECMWF_ERA5-monthly-reanalysis-MSLP_*.nc') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0d5741",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Regrid slp\n",
    "mslp_highres = mslp.sel(expver=1).msl/100  #do do not need the experimental/recent data because socat is only up till end of the prior yer. Also Pa to HPa. \n",
    "    #Note the expver variable indicates new experimental data: #https://confluence.ecmwf.int/pages/viewpage.action?pageId=173385064\n",
    "    #Data in recent 3 months will be blank with expver = 1 but this is expected and filtered next\n",
    "mslp_highres = mslp_highres.sel(time=slice(str(processed_start_yearmonth),str(processed_end_yearmonth))) #already monthly so select desired years\n",
    "mslp_highres = xr.Dataset({'mslp':(['time','latitude','longitude'],mslp_highres.data),'time':(['time'],mslp_highres.time.data),'latitude':(['latitude'],mslp_highres.latitude.data),'longitude':(['longitude'],mslp_highres.longitude.data)})\n",
    "mslp_highres_regridder = xesmf.Regridder(mslp_highres, ideal_grid, 'bilinear', periodic=True) #See note above about bilinear vs conservative\n",
    "mslp_out = mslp_highres_regridder(mslp_highres.chunk(-1), keep_attrs=False)\n",
    "#mslp_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df068ad1-51b3-4f35-8d7e-781932455abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mslp_out = mslp_out.rename({'latitude': 'ylat','longitude': 'xlon'}) #rename to be consistent with prior work\n",
    "mslp_out = mslp_out.assign_coords(time=ttime) #overwrite time dimension to be midmonth\n",
    "mslp_out.mslp.attrs['units'] = 'hPa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce140348",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_xarray_with_date(mslp_out, data_folder_root+'SLP/processed/', 'SLP_ECMWF_ERA5-monthly-reanalysis-1x1-MSLP', output_file_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffbc48a-8a20-47d9-a594-e6d05d047072",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(figsizew,figsizeh))\n",
    "plt.contourf(ideal_grid.longitude,ideal_grid.latitude,mslp_out.mslp.sel(time='2022-12-15').data) #just choosing one month from prior year\n",
    "plt.title('SLP (last month of prior year)'); plt.xlabel('Lon'); plt.ylabel('Lat')\n",
    "plt.colorbar().set_label('hPa');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a903eea-bd8f-493d-826c-cc4a1e35579f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23101b55",
   "metadata": {},
   "source": [
    "## pCO2\n",
    "### fCO2 SOCAT"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6ecec40c",
   "metadata": {},
   "source": [
    "General Process:\n",
    "1. Ingest SLP and fCO2\n",
    "2. Regrid and align to time frame\n",
    "3. Calculate pCO2 from these variables\n",
    "4. Compile new xarray dataset and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e9d7c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "socat = xr_open_dataset_custom(data_folder_root+r'pCO2/originals/fCO2_SOCOVV_SOCAT-gridded-monthly_2022.nc') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7db8aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get relevant variables and filter for desired years \n",
    "co2_processed_end_yearmonth = socat.tmnth.max().data.astype('datetime64[s]').item().strftime('%Y-%m') #Note that fCO2 is only up til 2 years ago if (released every June)\n",
    "fco2 = socat.fco2_ave_weighted\n",
    "fco2 = fco2.sel(tmnth=slice(str(processed_start_yearmonth),str(co2_processed_end_yearmonth))) \n",
    "fco2_sst = socat.sst_ave_weighted\n",
    "fco2_sst = fco2_sst.sel(tmnth=slice(str(processed_start_yearmonth),str(co2_processed_end_yearmonth)))\n",
    "fco2_mslp = mslp_out.mslp  #from ERA5 section above\n",
    "fco2_mslp = fco2_mslp.sel(time=slice(str(processed_start_yearmonth),str(co2_processed_end_yearmonth)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf3dd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For anlaysis, we only need fco2; however we are including a pco2 variable for additional validation and testing\n",
    "    #example: fCO2_to_pCO2(380, 8) #381.5\n",
    "pco2 = fCO2_to_pCO2(fco2, fco2_sst, fco2_mslp, tempEQ_C=None)\n",
    "pco2 = np.where((pco2>200)&(pco2<650),pco2,np.nan) #where socat pco2 values are <200 and >650 we are changing to nans as a source of quality control\n",
    "fco2 = xr.where((fco2>200)&(fco2<650),fco2,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e6508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realign time to our grid for each available month (ex shift from 16th to 15th for consistency)\n",
    "fco2_ttime = ttime[pd.DataFrame(ttime,columns=['t']).t.between(fco2.tmnth.min().data.astype('datetime64[s]').item().strftime('%Y-%m'), fco2.tmnth.max().data.astype('datetime64[s]').item(), inclusive='both')]\n",
    "    #Alternatively can use this: fco2_ttime = pd.date_range(start=fco2.tmnth.min().item(), end=fco2.tmnth.max().item(),freq='MS') + np.timedelta64(14, 'D')\n",
    "#fco2_ttime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c479775d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pco2_out = xr.Dataset(  {\n",
    "                        'pco2':([\"time\",\"ylat\",\"xlon\"],pco2.data),\n",
    "                        #'socat_mask':([\"time\",\"ylat\",\"xlon\"],np.where(~np.isnan(pco2),1,np.nan)),  #Prior code included additional variables which are not needed\n",
    "                        #'socat_sst':([\"time\",\"ylat\",\"xlon\"],fco2_sst.data),\n",
    "                        #'mslp':([\"time\",\"ylat\",\"xlon\"],fco2_mslp.data),\n",
    "                        'fco2':([\"time\",\"ylat\",\"xlon\"],fco2.data)\n",
    "                        },\n",
    "                        coords={'time': (['time'],fco2_ttime.values),\n",
    "                          'ylat': (['ylat'],fco2.ylat.data),\n",
    "                          'xlon': (['xlon'],fco2.xlon.data)}\n",
    "                    )\n",
    "pco2_out.pco2.attrs['units'] = 'uatm'\n",
    "pco2_out.pco2.attrs['description'] = 'uses fco2 (weighted), sst (weighted) and MSLP to convert to pCO2 via fCO2_to_pCO2 script'\n",
    "pco2_out.pco2.attrs['description2'] = 'socat pco2 and fco2 values <200 and >650 have been changed to nans as a source of quality control' \n",
    "#pco2_out.socat_sst.attrs['units'] = 'deg C'\n",
    "#pco2_out.mslp.attrs['units'] = 'hPa'\n",
    "pco2_out.fco2.attrs['units'] = 'uatm'\n",
    "#pco2_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf51d3b-46c4-4238-8ee0-69a28ff167da",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_xarray_with_date(pco2_out.chunk(-1), data_folder_root+'pCO2/processed/', 'pCO2_LEAP_SOCAT-ERA5-fco2-weighted-gridded', output_file_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6df0a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(figsizew,figsizeh))\n",
    "plt.contourf(ideal_grid.longitude,ideal_grid.latitude,np.nanmax(pco2_out.fco2, axis=0)) \n",
    "plt.title('Max fCO2 (across time)'); plt.xlabel('Lon'); plt.ylabel('Lat')\n",
    "plt.colorbar().set_label('uatm');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e7342a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6337dc3d-872d-4f4b-803a-95b75bddeebd",
   "metadata": {},
   "source": [
    "### Coastal Fill pCO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3170e8-4cd7-47ea-bd09-30b529327ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "coastal_clim = xr_open_dataset_custom(data_folder_root + 'pCO2/originals/pCO2_NOAA-NCEI_MPI-ULB-SOM-FFN_1988-2020.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4eaab4-442c-4767-a82d-73a86bf83363",
   "metadata": {},
   "outputs": [],
   "source": [
    "coastal_clim = coastal_clim.where(coastal_clim != -999) #fill negative values (land) with nan\n",
    "\n",
    "#Regrid\n",
    "coastal_clim_regridder = xesmf.Regridder(coastal_clim, ideal_grid, 'conservative', periodic=True)  #see notes above on why conservative over bilinear\n",
    "coastal_clim_out = coastal_clim_regridder(coastal_clim.chunk(-1), keep_attrs=True)\n",
    "#coastal_clim_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d791c572-f063-465c-a5a3-00ffe55b33d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert pco2 to fco2\n",
    "#The data is centered on 2006 so we'll convert this Landschutzer climatology product to fco2 using inputs for the year 2006 from SLP and SST\n",
    "#Note that this requires SST and SLP from above\n",
    "coastal_clim_out_fco2 = pCO2_to_fCO2(coastal_clim_out.pco2, \n",
    "                                     sst_out.sst.sel(time=slice(str('2006-01'),str('2006-12'))),\n",
    "                                     mslp_out.mslp.sel(time=slice(str('2006-01'),str('2006-12'))),\n",
    "                                     tempEQ_C=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7340d90f-5459-4969-a601-9c7944a7b522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we now have 12 months of coastal fco2 data, let's replicate for the desired time frame so merging is easier later\n",
    "coastal_out_full_fco2 = np.empty(shape=(len(ttime),180,360)) \n",
    "#now fill array with climatology\n",
    "for i, m in enumerate(ttime): \n",
    "    coastal_out_full_fco2[i,:,:] = coastal_clim_out_fco2[m.month-1,:,:]\n",
    "#coastal_out_full_fco2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55481a51-522e-4874-916e-5ef3dca37b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "coastal_out_full_fco2_xr = xr.Dataset({'fco2':([\"time\",\"ylat\",\"xlon\"],coastal_out_full_fco2.data)},\n",
    "                    coords={'time': (['time'],ttime.values),'ylat':(['ylat'],ideal_grid.latitude.data),'xlon':(['xlon'],ideal_grid.longitude.data)})\n",
    "coastal_out_full_fco2_xr.fco2.attrs['description'] = 'uses pco2, NOAA sst and ERA5 MSLP to convert pCO2 to fCO2 using pCO2_to_fCO2 script'\n",
    "coastal_out_full_fco2_xr.fco2.attrs['units'] = 'uatm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911c6212-02be-46c3-b9b6-df19b4d4c2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_xarray_with_date(coastal_out_full_fco2_xr, data_folder_root+'pCO2/processed/', 'fCO2_NOAA-NCEI_MPI-ULB-SOM-FFN', output_file_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cf451b-6bc6-4722-b7fd-02710421456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(figsizew,figsizeh))\n",
    "#plt.contourf(ideal_grid.longitude,ideal_grid.latitude,np.nanmax(coastal_out_full_fco2_xr.fco2, axis=0)) #max across time \n",
    "plt.contourf(ideal_grid.longitude,ideal_grid.latitude,coastal_out_full_fco2_xr.fco2.sel(time='2006-06-15')) #just one specific month\n",
    "plt.title('Coastal File fCO2'); plt.xlabel('Lon'); plt.ylabel('Lat')\n",
    "plt.colorbar().set_label('uatm');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6642700d-faf5-438d-a11b-48d6b199541d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a81b979a",
   "metadata": {},
   "source": [
    "# Atmospheric CO2 (xCO2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa0060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data was downloaded monthly as csv. Convert to a xarray\n",
    "#Note that the number of header rows (55) is hardcoded here\n",
    "xco2_df = pd.read_csv(data_folder_root+r'xCO2/originals/xCO2_NOAA_xCO2-mm-gl-monthly_197901-202402.csv', skiprows=38)  ## NEED TO UPDATE TO LATEST MONTH AND CHANGE Skiprows=38 (was 55)\n",
    "        #previously was xCO2_NOAA_xCO2-mm-gl-monthly_197901-202306.csv\n",
    "#xco2_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98d26fb-b9e8-415b-bd43-3910f2d15368",
   "metadata": {},
   "outputs": [],
   "source": [
    "xco2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed15fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make time the index; drop unneeded columns; convert to xarray\n",
    "xco2_df['time'] = xco2_df.apply(lambda row: datetime.datetime(int(row.year), int(row.month), 15), axis=1) #putting as 15th of the month\n",
    "xco2_df['time'] = pd.to_datetime(xco2_df.time)\n",
    "xco2_df.index = pd.DatetimeIndex(xco2_df.time)\n",
    "\n",
    "xco2_xr = xco2_df[['trend']].to_xarray() #we only want the \"trend\" field because it matches historical work that did not factor seasonality \n",
    "xco2_xr_filtered = xco2_xr.sel(time=slice(str(processed_start_yearmonth),str(processed_end_yearmonth))) #filter for desired time\n",
    "xco2_xr_filtered = xco2_xr_filtered.rename({'trend': 'xco2_trend'})\n",
    "#xco2_xr_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1010393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_xarray_with_date(xco2_xr_filtered, data_folder_root+'xCO2/processed/', 'xCO2_NOAA_xCO2-mm-gl-monthly', output_file_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44f72de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(figsizew,figsizeh))\n",
    "plt.plot(xco2_xr_filtered.time,xco2_xr_filtered.xco2_trend)\n",
    "plt.title('Atmospheric CO2 (trend)'); plt.xlabel('Year'); plt.ylabel('xCO2 (uatm)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3186654",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
