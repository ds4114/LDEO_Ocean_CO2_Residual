{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url: str, dest_folder: str, dest_file: str, overwrite=False, create_dest=False):\n",
    "    \"\"\"\n",
    "    Wrapper function to download data from a URL and save it to a folder. If the destination path is Google Cloud Storage and the\n",
    "    source data is a netcdf, the downloaded data will be saved as a .zarr file\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url : string\n",
    "        The URL to the direct download\n",
    "    dest_folder: string\n",
    "        Desired file path for the destination folder\n",
    "    dest_file: string\n",
    "        Desired file name for the downloaded file\n",
    "    overwrite: boolean\n",
    "        if true, will overwrite the dest_file at the dest_folder location\n",
    "    create_dest: boolean\n",
    "        if true, the destination folder will be created automatically;\n",
    "        otherwise, the function will stop and require a user to manually create the folder as an extra validation step\n",
    "    \"\"\"\n",
    "    \n",
    "    if dest_folder[0:5] == 'gs://':\n",
    "        if url[-3:] == '.nc':\n",
    "            download_to_gs_as_zarr(url, dest_folder, dest_file, overwrite, create_dest)\n",
    "        else:\n",
    "            print('Cancelling - This cloud storage function currently only supports transfer of netcdf files; please confirm the download file extension.')\n",
    "            return None\n",
    "    else:\n",
    "        download_to_folder(url, dest_folder, dest_file, overwrite, create_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some modification may be needed for additional operating systems\n",
    "def download_to_folder(url: str, dest_folder: str, dest_file: str, overwrite=False, create_dest=False):\n",
    "    \"\"\"\n",
    "    Downloads data from a URL and saves it to a folder\n",
    "    Modified from https://stackoverflow.com/questions/56950987/download-file-from-url-and-save-it-in-a-folder-python\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url : string\n",
    "        The URL to the direct download\n",
    "    dest_folder: string\n",
    "        File path for the destination folder\n",
    "    dest_file: string\n",
    "        File name for the downloaded file\n",
    "    overwrite: boolean\n",
    "        if true, will overwrite the dest_file at the dest_folder location\n",
    "    create_dest: boolean\n",
    "        if true, the destination folder will be created automatically;\n",
    "        otherwise, the function will stop and require a user to manually create the folder as an extra validation step\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import requests\n",
    "    \n",
    "    if os.path.exists(dest_folder):\n",
    "        pass\n",
    "    else:\n",
    "        if create_dest:\n",
    "            os.makedirs(dest_folder)  # create folder if it does not exist\n",
    "        else:\n",
    "            print(f\"Please confirm the destination folder exists: {dest_folder}. Or set create_dest=True.\")  #extra check to place data in correct spot\n",
    "            return None\n",
    "\n",
    "    file_path = os.path.join(dest_folder, dest_file)\n",
    "    \n",
    "    if overwrite or not (os.path.isfile(file_path)):   #if you want to overwrite or if the file doesnt already exists, then download\n",
    "        r = requests.get(url, stream=True)\n",
    "        if r.ok:\n",
    "            print(f\"Saving {url} to {file_path}...\")\n",
    "            with open(file_path, 'wb') as f:\n",
    "                for chunk in r.iter_content(chunk_size=1024 * 1024 * 10):  #10 MB chunk size; could increase for faster download speed\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "                        f.flush()\n",
    "                        os.fsync(f.fileno())\n",
    "            print(\"Complete\")\n",
    "        else:  # HTTP status code 4XX/5XX. This could be incorporated into a try/catch to handle separately\n",
    "            print(f\"Download failed: status code {r.status_code}\\n{r.text}\")\n",
    "            print(url)\n",
    "    else:\n",
    "        print(f\"File {dest_file} already exists at {dest_folder} - (skipping download from {url} )\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some modification may be needed for additional operating systems\n",
    "def download_to_gs_as_zarr(url: str, dest_folder: str, dest_file: str, overwrite=False, create_dest=False):\n",
    "    \"\"\"\n",
    "    Downloads NetCDF data from a URL and saves it to a temporary folder; then loads and copies it to destination Google Storage as a zarr file\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url : string\n",
    "        The URL to the direct download\n",
    "    dest_folder: string\n",
    "        File path for the destination folder\n",
    "    dest_file: string\n",
    "        File name for the downloaded file\n",
    "    overwrite: boolean\n",
    "        if true, will overwrite the dest_file at the dest_folder location\n",
    "    create_dest: boolean\n",
    "        if true, the destination folder will be created automatically;\n",
    "        otherwise, the function will stop and require a user to manually create the folder as an extra validation step\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import requests\n",
    "    import gcsfs\n",
    "    import xarray as xr\n",
    "    \n",
    "    fs = gcsfs.GCSFileSystem()\n",
    "    file_path = os.path.join(dest_folder, dest_file)\n",
    "    zarr_dest_file = dest_file.replace('.nc','.zarr')  #hardcoded for netcdfs\n",
    "    zarr_file_path = file_path.replace('.nc','.zarr')\n",
    "    tmp_file_path = '../tmp/'+dest_file\n",
    "    \n",
    "    #check if destination path exists\n",
    "    if fs.exists(dest_folder):\n",
    "        pass\n",
    "    else:\n",
    "        if create_dest:\n",
    "            print(f\"Creating destination folder: {dest_folder}...\")  \n",
    "            fs.touch(dest_folder) #create empty file to organize folder structure\n",
    "        else:\n",
    "            print(f\"Please confirm the destination folder exists using the touch() function: {dest_folder}. Or set create_dest=True.\")  #extra check to place data in correct spot\n",
    "            return None\n",
    "    \n",
    "    #check if file already exists in destination\n",
    "    if fs.exists(zarr_file_path) and (not overwrite):\n",
    "        #TODO - the exists() function seems unstable; if you remove files from another kernels the result may not register\n",
    "        print(f\"File {zarr_dest_file} already exists at {dest_folder} - (skipping download from {url} )\")\n",
    "        return None\n",
    "    \n",
    "    #download to temp folder\n",
    "    print(f\"Downloading to ../tmp/...\")    \n",
    "    download_to_folder(url, '../tmp/', dest_file, overwrite=overwrite, create_dest=True)\n",
    "    \n",
    "    #copy to destination\n",
    "    tmp_xr = xr.open_dataset(tmp_file_path)\n",
    "    print(f\"Transferring to GS {zarr_file_path}...\")\n",
    "    tmp_xr.to_zarr(zarr_file_path, mode='w')\n",
    "    \n",
    "    #remove temp file\n",
    "    os.remove(tmp_file_path)\n",
    "    print(\"Complete\")\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdsapi_custom_download(year: int,  months: list, variable: str, dest_folder: str, dest_file: str\n",
    "                          ,overwrite=False, create_dest=False ):\n",
    "    \"\"\"\n",
    "    Downloads data using the cdsapi (European Centre for Medium-Range Weather Forecasts)\n",
    "    If the destination folder is cloud storage, the function saves the file to a temporary folder; then loads and copies it to destination Google Storage as a zarr file\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    year: int\n",
    "        The year of the data to be downloaded\n",
    "    months:\n",
    "        A list of months (set of integers from 1 to 12) of the data to be downloaded\n",
    "    dest_folder: string\n",
    "        Local file path for the destination folder\n",
    "    dest_file: string\n",
    "        Local file name for the downloaded file\n",
    "    overwrite: boolean\n",
    "        if true, will overwrite the dest_file at the dest_folder location\n",
    "    create_dest: boolean\n",
    "        if true, the destination folder will be created automatically;\n",
    "        otherwise, the function will stop and require a user to manually create the folder as an extra validation step\n",
    "    \"\"\"\n",
    "    import cdsapi\n",
    "    import os\n",
    "    import requests\n",
    "    import xarray as xr\n",
    "    import gcsfs\n",
    "    \n",
    "    file_path = os.path.join(dest_folder, dest_file)\n",
    "    gfs = False\n",
    "    if dest_folder[0:5] == 'gs://':\n",
    "        gfs = True\n",
    "        fs = gcsfs.GCSFileSystem()\n",
    "        zarr_dest_file = dest_file.replace('.nc','.zarr')  #hardcoded for netcdfs\n",
    "        zarr_file_path = file_path.replace('.nc','.zarr')\n",
    "        tmp_file_path = '../tmp/'+dest_file\n",
    "    \n",
    "    #check if destination path exists\n",
    "    if gfs:\n",
    "        if not (fs.exists(dest_folder)):\n",
    "            if create_dest:   #if dest folder doesnt exist but we want to create it\n",
    "                print(f\"Creating destination folder: {dest_folder}...\")  \n",
    "                fs.touch(dest_folder) #create empty file to organize folder structure\n",
    "            else:\n",
    "                print(f\"Please confirm the destination folder exists using the touch() function: {dest_folder}. Or set create_dest=True.\")  #extra check to place data in correct spot\n",
    "                return None\n",
    "    else:\n",
    "        if not (os.path.exists(dest_folder)):\n",
    "            if create_dest:\n",
    "                os.makedirs(dest_folder)  \n",
    "            else:\n",
    "                print(f\"Please confirm the destination folder exists: {dest_folder}. Or set create_dest=True.\")  #extra check to place data in correct spot\n",
    "                return None\n",
    "    \n",
    "    #check if data already exists or was previously downloaded\n",
    "    if gfs:\n",
    "        if fs.exists(zarr_file_path) and (not overwrite):\n",
    "            print(f\"File {zarr_dest_file} already exists - (skipping download for {year} )\")\n",
    "            return None\n",
    "    else:\n",
    "        if os.path.isfile(file_path) and (not overwrite):  \n",
    "            print(f\"File {dest_file} already exists - (skipping download from {year} )\")\n",
    "            return None\n",
    "    \n",
    "    #now download to temp folder\n",
    "    if not os.path.exists('../tmp'): os.makedirs('../tmp')\n",
    "    #print(f\"Downloading to ../tmp...\")    \n",
    "    c = cdsapi.Client()\n",
    "    c.retrieve(\n",
    "        'reanalysis-era5-single-levels-monthly-means',\n",
    "        {\n",
    "            'format': 'netcdf',\n",
    "            'year': year,\n",
    "            'variable': variable,\n",
    "            'product_type': 'monthly_averaged_reanalysis',\n",
    "            'month': months,\n",
    "            'time': '00:00'\n",
    "        },\n",
    "        tmp_file_path)\n",
    "    \n",
    "    if gfs: #load and transfer as zarr\n",
    "        tmp_xr = xr.open_dataset(tmp_file_path)\n",
    "        print(f\"Transferring to GS {zarr_file_path}...\")\n",
    "        tmp_xr.to_zarr(zarr_file_path, mode='w')\n",
    "    else:\n",
    "        tmp_xr = xr.open_dataset(tmp_file_path)\n",
    "        print(f\"Transferring to Destination {file_path}...\")\n",
    "        tmp_xr.to_netcdf(file_path)\n",
    "    \n",
    "    os.remove(tmp_file_path)\n",
    "    return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_xarray_with_date(out_xarray, dest_folder: str, dest_filename: str, filetype='.nc', with_date=True, overwrite=False):\n",
    "    \"\"\"\n",
    "    Outputs a file to a specified location and names it according to the date range contained in the xarray\n",
    "    Must have a coordinate dimension named 'time' if outputting with_date=True\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    out_xarray : xarray dataset\n",
    "        The object to output as a netCDF or Zarr file\n",
    "    dest_folder: string\n",
    "        file path for the destination folder\n",
    "    dest_file: string\n",
    "        file name desired for the output data (without specifying the filetype)\n",
    "    filetype: str\n",
    "        Either '.nc' or '.zarr'; specifying the type of output\n",
    "    with_date: boolean\n",
    "        if true, the time range of the xarray (using dimension \"time\") will be appended to the end of file name as '_YYYMM-YYYYMM'\n",
    "    overwrite: boolean\n",
    "        if true, will overwrite the dest_file at the dest_folder location\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import xarray\n",
    "    \n",
    "    #clean up if file name already includes the filetype suffix\n",
    "    dest_filename_new = dest_filename\n",
    "    if dest_filename.strip()[-3:] == '.nc':\n",
    "        dest_filename_new = dest_filename.strip()[:-3]\n",
    "    elif dest_filename.strip()[-5:] == '.zarr':\n",
    "        dest_filename_new = dest_filename.strip()[:-5]\n",
    "    \n",
    "    if with_date:\n",
    "        min_yearmonth = str(out_xarray.time.min().data.astype('datetime64[s]').item().strftime('%Y%m')) #just gets the min date from the xarray in YYYYMM format\n",
    "        max_yearmonth = str(out_xarray.time.max().data.astype('datetime64[s]').item().strftime('%Y%m')) \n",
    "    \n",
    "        processed_filename = (dest_filename_new + '_' + min_yearmonth + '-' + max_yearmonth + filetype)\n",
    "        processed_file_path = os.path.join(dest_folder, processed_filename)\n",
    "        #print(processed_file_path)\n",
    "    else:\n",
    "        processed_filename = dest_filename_new + filetype\n",
    "        processed_file_path = os.path.join(dest_folder, processed_filename)\n",
    "    \n",
    "    #check if file already exists\n",
    "    already_exists = False\n",
    "    if os.path.isfile(processed_file_path): already_exists = True\n",
    "    if dest_folder[0:5] == 'gs://':\n",
    "        import gcsfs\n",
    "        fs = gcsfs.GCSFileSystem()\n",
    "        if fs.exists(processed_file_path):\n",
    "            already_exists = True\n",
    "    \n",
    "    if overwrite or not (already_exists):   #if you want to overwrite or if the file doesnt already exists, then save\n",
    "        if filetype == '.nc':\n",
    "            out_xarray.to_netcdf( processed_file_path )\n",
    "            print(f\"Saved {processed_filename} to {dest_folder}\")\n",
    "        elif filetype == '.zarr':\n",
    "            out_xarray.to_zarr( processed_file_path, mode='w')\n",
    "            print(f\"Saved {processed_filename} to {dest_folder}\")\n",
    "        else: \n",
    "            print(\"Unsupported file output type; please choose '.nc' or '.zarr'\")\n",
    "    else:\n",
    "        print(f\"Cancelling output - {processed_filename} already exists in {dest_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XArray Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xr_open_dataset_custom(file :str, decode_times=True):\n",
    "    \"\"\"\n",
    "    Wrapper function for xarray.open_dataset() but compatible with either .nc (netcdf) or .zarr files.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file : string\n",
    "        The file location of an xarray dataset\n",
    "    decode_times : bool, optional\n",
    "        If True, decode times encoded in the standard NetCDF datetime format \n",
    "        into datetime objects. Otherwise, leave them encoded as numbers.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    xr : an xarray dataset object\n",
    "    \"\"\"\n",
    "    #correct if a user specified a .nc but meant .zarr on Google cloud:\n",
    "    updated_file = file\n",
    "    if file.strip()[0:5] == 'gs://' and file.strip()[-3:] == '.nc': \n",
    "        updated_file = file.strip()[0:-3]+file.strip()[-3:].replace('.nc','.zarr')  #hardcoded for netcdfs\n",
    "        \n",
    "    try:\n",
    "        xr_ds = xr.open_dataset(file, decode_times=decode_times) \n",
    "    except:\n",
    "        try:\n",
    "            xr_ds = xr.open_dataset(file, decode_times=decode_times, engine='zarr', chunks={})\n",
    "        except:\n",
    "            print(f'Encountered an error - trying with {updated_file}...')\n",
    "            xr_ds = xr.open_dataset(updated_file, decode_times=decode_times, engine='zarr', chunks={}) \n",
    "        \n",
    "    return xr_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xr_open_mfdataset_custom(file: str):\n",
    "    \"\"\"\n",
    "    Wrapper function for xarray.open_mfdataset() but compatible with either .netcdf or .zarr files.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file : string\n",
    "        The file location of an xarray dataset\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    xr : an xarray dataset object\n",
    "    \"\"\"\n",
    "    #correct if a user specified a .nc but meant .zarr on Google cloud:\n",
    "    updated_file = file\n",
    "    if file.strip()[0:5] == 'gs://' and file.strip()[-3:] == '.nc': \n",
    "        updated_file = file.strip()[0:-3]+file.strip()[-3:].replace('.nc','.zarr')  #hardcoded for netcdfs\n",
    "\n",
    "    try:\n",
    "        xr_ds = xr.open_mfdataset(file) \n",
    "    except:\n",
    "        try:\n",
    "            xr_ds = xr.open_mfdataset(file, engine='zarr', chunks={})  \n",
    "        except:\n",
    "            print(f'Encountered an error - trying with {updated_file}')\n",
    "            xr_ds = xr.open_mfdataset(updated_file, engine='zarr', chunks={})\n",
    "            print('Success.')\n",
    "        \n",
    "    return xr_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function was modified from Luke's\n",
    "def add_time_to_globcolour(file: str):\n",
    "    \"\"\"\n",
    "    Outputs an xarray dataset with a 'time' dimension based on an inputted file\n",
    "    Must have a date in the file name in the YYYYMM format at the end\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file : string\n",
    "        The file location of an xarray dataset that is missing a time dimension.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    ds_tmp : an xarray dataset with the additional time coordinate\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import xarray as xr\n",
    "    import re\n",
    "    \n",
    "    # extract start date\n",
    "    file_month = re.findall(r'\\d{4}\\d{2}', file[-10:])[0]  #just try to find first date in YYYYMM format in last 10 characters of file name\n",
    "    pd_datetime = pd.to_datetime(file_month, format='%Y%m') + np.timedelta64(14, 'D') #add days to be mid-month\n",
    "\n",
    "    # open dataset and create time coordinate and dimension\n",
    "    ds = xr_open_dataset_custom(file) #previously #ds = xr.open_dataset(file)\n",
    "    ds_tmp = ds.assign_coords({'time':pd_datetime}).expand_dims(dim='time', axis=0)\n",
    "    return ds_tmp\n",
    "\n",
    "#chl_test = add_time_to_globcolour(data_folder_root+'CHL/originals/CHL_ARI-ST-GlobColour_L3m-GLOB-100-merged-GSM-CHL1_199802.nc') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_or_0_xr(xr_to_upd, field_name):\n",
    "    \"\"\"\n",
    "    Function to compute the log (base 10) of a DataArray. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Input 1 : DataArray\n",
    "        must have time, ylat, xlon coordinates\n",
    "    Input 2 : String \n",
    "        desired name of the new log field in the output DataArray\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    res : a DataArray of the same shape with log values \n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import xarray as xr\n",
    "    from numpy import errstate,isneginf,array\n",
    "\n",
    "    with errstate(divide='ignore'):\n",
    "        n = np.log10(xr_to_upd).values #use .to_numpy() for newer versions of xr\n",
    "    n[np.isneginf(n)]=0\n",
    "    res = xr.DataArray(n, coords={'time': xr_to_upd.time,'ylat': xr_to_upd.ylat,'xlon': xr_to_upd.xlon}, dims=[\"time\", \"ylat\", \"xlon\"], name=field_name)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_least_date_range(xarraylist):\n",
    "    \"\"\"\n",
    "    Function to compute the minimum overlapping time range of a set of xarray datasets \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Input 1 : xarraylist\n",
    "        A list of xarray datasets. Each must contain a 'time' coordinate\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    min_date : string \n",
    "        The most recent start date (in YYYY-MM format) among the datasets \n",
    "    max_date : string\n",
    "        The earliest end date (in YYYY-MM format) among the datasets\n",
    "    \"\"\"\n",
    "    import xarray as xr\n",
    "    \n",
    "    min_date = []\n",
    "    max_date = []\n",
    "    for f in xarraylist:\n",
    "        min_date.append(f.time.min().data.astype('datetime64[s]').item())\n",
    "        max_date.append(f.time.max().data.astype('datetime64[s]').item())\n",
    "    \n",
    "    return max(min_date).strftime('%Y-%m'), min(max_date).strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fCO2_to_pCO2\n",
    "\n",
    "These functions were taken from the fCO2_to_pCO2.ipynb file with no changes other than variable naming updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnitError(Exception):\n",
    "    pass\n",
    "\n",
    "def check_array_bounds(arr, lims, action=\"warn\", name=\"\"):\n",
    "    \"\"\"\n",
    "    Checks that units are within the given limits. If not, then\n",
    "    will raise/warn the user. Will always raise an error if more\n",
    "    than half of the non-nan values are outside the limits.\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : array-like\n",
    "        The array that will be checked\n",
    "    lims : tuple\n",
    "        lower and upper limits of checks\n",
    "        note that limits are exclusive (i.e. < and >, and not >=/<=)\n",
    "    action: string\n",
    "        raise - will raise an error and not continue\n",
    "        warn - will throw a warning and mask values with nan\n",
    "        quiet - same as warn, but without warning\n",
    "        ignore - nothing will be done, but may result in bad data\n",
    "    name: string\n",
    "        if given, will inform the user of the name of the array\n",
    "        to make debugging easier\n",
    "    Return\n",
    "    ------\n",
    "    arr : array-like\n",
    "        returns the array, but if warn or quiet, will be masked\n",
    "        with nans\n",
    "    \"\"\"\n",
    "\n",
    "    from numpy import array, any, nan, isnan\n",
    "    from warnings import warn\n",
    "\n",
    "    arr = array(arr, ndmin=1, dtype=float)\n",
    "    if arr.size <= 2:\n",
    "        return arr\n",
    "\n",
    "    outside = (arr < lims[0]) | (arr > lims[1])\n",
    "\n",
    "    non_nan_count = arr.size - isnan(arr).sum()\n",
    "    half_outside = outside.sum() > (non_nan_count * 0.5)\n",
    "    if half_outside:\n",
    "        raise UnitError(\n",
    "            f\"More than half of the values in {name} are outside the limits \"\n",
    "            f\"{str(lims)}. Check that input contains the correct units.\"\n",
    "        )\n",
    "\n",
    "    msg = (\n",
    "        f\"There are {outside.sum():d} values that do not fall within \"\n",
    "        f\"the given limits {str(lims)}\"\n",
    "        f\" of {name}\"\n",
    "        if name != \"\"\n",
    "        else \"\"\n",
    "    )\n",
    "\n",
    "    if any(outside) & (action == \"raise\"):\n",
    "        raise UnitError(msg)\n",
    "    elif action == \"warn\":\n",
    "        if any(outside):\n",
    "            warn(msg, Warning)\n",
    "        arr[outside] = nan\n",
    "    elif action == \"quiet\":\n",
    "        arr[outside] = nan\n",
    "    elif action == \"ignore\":\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception(\"action must have raise/warn/quiet/ignore as inputs\")\n",
    "\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_K(temp_K):\n",
    "    return check_array_bounds(\n",
    "        arr=temp_K, lims=(270, 318.5), action=\"warn\", name=\"temperature (K)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pres_atm(pres_atm):\n",
    "    return check_array_bounds(\n",
    "        arr=pres_atm, lims=(0.5, 1.5), action=\"warn\", name=\"Pressure (atm)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CO2_mol(CO2_mol):\n",
    "    return check_array_bounds(\n",
    "        arr=CO2_mol,\n",
    "        lims=(5e-6, 0.08),\n",
    "        action=\"warn\",\n",
    "        name=\"CO2 mole fraction (ppm)\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temperature_correction(temp_in, temp_out):\n",
    "    \"\"\"\n",
    "    Calculate a correction factor for the temperature difference between the\n",
    "    intake and equilibrator. This is based on the empirical relationship used\n",
    "    in Takahashi et al. 1993.\n",
    "    pCO2_Tout = pCO2_Tin * T_factor\n",
    "    Parameters\n",
    "    ----------\n",
    "    temp_in : np.array\n",
    "        temperature at which original pCO2 is measured\n",
    "    temp_out : np.array\n",
    "        temperature for which pCO2 should be represented\n",
    "    Return\n",
    "    ------\n",
    "    factor : np.array\n",
    "        a correction factor to be multiplied to pCO2 (unitless)\n",
    "    References\n",
    "    ----------\n",
    "    Takahashi, Taro et al. (1993). Seasonal variation of CO2 and nutrients in\n",
    "        the high-latitude surface oceans: A comparative study. Global\n",
    "        Biogeochemical Cycles, 7(4), 843–878. https://doi.org/10.1029/93GB02263\n",
    "    \"\"\"\n",
    "\n",
    "    from numpy import array, exp\n",
    "\n",
    "    # see the Takahashi 1993 paper for full description\n",
    "\n",
    "    Ti = array(temp_in)\n",
    "    To = array(temp_out)\n",
    "\n",
    "    factor = exp(0.0433 * (To - Ti) - 4.35e-05 * (To ** 2 - Ti ** 2))\n",
    "\n",
    "    return factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def virial_coeff(temp_K1, pres_atm1, xCO2_mol=None):\n",
    "    \"\"\"\n",
    "    Calculate the ideal gas correction factor for converting pCO2 to fCO2.\n",
    "    fCO2 = pCO2 * virial_expansion\n",
    "    pCO2 = fCO2 / virial_expansion\n",
    "    Based on the Lewis and Wallace 1998 Correction.\n",
    "    Parameters\n",
    "    ----------\n",
    "    press_atm : np.array\n",
    "        uncorrected pressure in atm\n",
    "    temp_K : np.array\n",
    "        temperature in degrees Kelvin\n",
    "    xCO2_mol : np.array\n",
    "        mole fraction of CO2. Can be pCO2/fCO2 if xCO2 is not defined or can\n",
    "        leave this as undefined as makes only a small impact on output\n",
    "    Return\n",
    "    ------\n",
    "    virial_expression : np.array\n",
    "        the factor to multiply with pCO2. Unitless\n",
    "    Examples\n",
    "    --------\n",
    "    The example below is from Dickson et al. (2007)\n",
    "    >>> 350 * virial_coeff(298.15, 1)  # CO2 [uatm] * correction factor\n",
    "    348.8836492182758\n",
    "    References\n",
    "    ----------\n",
    "    Weiss, R. (1974). Carbon dioxide in water and seawater: the solubility of a\n",
    "        non-ideal gas. Marine Chemistry, 2(3), 203–215.\n",
    "        https://doi.org/10.1016/0304-4203(74)90015-2\n",
    "    Compared with the Seacarb package in R\n",
    "    \"\"\"\n",
    "    from numpy import array, exp\n",
    "    #import check_units as check\n",
    "\n",
    "    T = temp_K(temp_K1)\n",
    "    P = pres_atm(pres_atm1)\n",
    "    C = array(xCO2_mol)\n",
    "    R = 82.057  # gas constant for ATM\n",
    "\n",
    "    temp_K(T)\n",
    "    pres_atm(P)\n",
    "\n",
    "    # B is the virial coefficient for pure CO2\n",
    "    B = -1636.75 + 12.0408 * T - 0.0327957 * T ** 2 + 3.16528e-5 * T ** 3\n",
    "    # d is the virial coefficient for CO2 in air\n",
    "    d = 57.7 - 0.118 * T\n",
    "\n",
    "    # \"x2\" term often neglected (assumed = 1) in applications of Weiss's\n",
    "    # (1974) equation 9\n",
    "    if xCO2_mol is not None:\n",
    "        CO2_mol(C)\n",
    "        x2 = (1 - C) ** 2\n",
    "    else:\n",
    "        x2 = 1\n",
    "\n",
    "    ve = exp(P * (B + 2 * x2 * d) / (R * T))\n",
    "\n",
    "    return ve\n",
    "\n",
    "#350 * virial_coeff(298.15, 1) #348.88364922"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is not required in this set of code but preserving for other use\n",
    "def fCO2_to_pCO2(fCO2SW_uatm, tempSW_C, pres_hPa=1013.25, tempEQ_C=None):\n",
    "    \"\"\"\n",
    "    Convert fCO2 to pCO2 for SOCAT in sea water. A simple version of the\n",
    "    equation would simply be:\n",
    "        pCO2sw = fCO2sw / virial_exp\n",
    "    where the virial expansion is calculated without xCO2\n",
    "    We get a simple approximate for equilibrator xCO2 with:\n",
    "        xCO2eq = fCO2sw * deltaTemp(sw - eq) / press_eq\n",
    "    pCO2sw is then calculated with:\n",
    "        pCO2sw = fCO2sw / virial_exp(xCO2eq)\n",
    "    Parameters\n",
    "    ----------\n",
    "    fCO2SW_uatm : array\n",
    "        seawater fugacity of CO2 in micro atmospheres\n",
    "    tempSW_C : array\n",
    "        sea water temperature in degrees C\n",
    "    pres_hPa : array\n",
    "        equilibrator pressure in hecto Pascals\n",
    "    tempEQ_C : array\n",
    "        equilibrator temperature in degrees C\n",
    "    Returns\n",
    "    -------\n",
    "    pCO2SW_uatm : array\n",
    "        partial pressure of CO2 in seawater\n",
    "    Note\n",
    "    ----\n",
    "    In FluxEngine, they account fully solve for the original xCO2 that is used\n",
    "    in the calculation of the virial exponent. I use the first estimate of\n",
    "    xCO2 (based on fCO2 rather than pCO2). The difference between the two\n",
    "    approaches is so small that it is not significant to be concerned. Their\n",
    "    correction is more precise, but the difference between their iterative\n",
    "    correction and our approximation is on the order of 1e-14 atm (1e-8 uatm).\n",
    "    Examples\n",
    "    --------\n",
    "    >>> fCO2_to_pCO2(380, 8)\n",
    "    381.50806485658234\n",
    "    >>> fCO2_to_pCO2(380, 8, pres_hPa=985)\n",
    "    381.4659553134281\n",
    "    >>> fCO2_to_pCO2(380, 8, pres_hPa=985, tempEQ_C=14)\n",
    "    381.466027968504\n",
    "    \"\"\"\n",
    "    #import check_units as check\n",
    "    #import auxiliary_equations as eqs\n",
    "\n",
    "    # if equilibrator inputs are None, tempEQ=tempSW\n",
    "    if tempEQ_C is None:\n",
    "        tempEQ_was_None = True\n",
    "        tempEQ_C = tempSW_C\n",
    "    else:\n",
    "        tempEQ_was_None = False\n",
    "\n",
    "    # standardise the inputs and convert units\n",
    "    fCO2sw = CO2_mol(fCO2SW_uatm * 1e-6)\n",
    "    Tsw = temp_K(tempSW_C + 273.15)\n",
    "    Teq = temp_K(tempEQ_C + 273.15)\n",
    "    Peq = pres_atm(pres_hPa / 1013.25)\n",
    "\n",
    "    # calculate the CO2 diff due to equilibrator and seawater temperatures\n",
    "    # if statement is there to save a bit of time\n",
    "    if tempEQ_was_None:\n",
    "        dT = 1.0\n",
    "    else:\n",
    "        dT = temperature_correction(Tsw, Teq)\n",
    "\n",
    "    # a best estimate of xCO2 - this is an aproximation\n",
    "    # one would have to use pCO2 / Peq to get real xCO2\n",
    "    # Not getting the exact equilibrator xCO2\n",
    "    xCO2eq = fCO2sw * dT / Peq\n",
    "\n",
    "    pCO2SW = fCO2sw / virial_coeff(Tsw, Peq, xCO2eq)\n",
    "    pCO2SW_uatm = pCO2SW * 1e6\n",
    "\n",
    "    return pCO2SW_uatm\n",
    "\n",
    "#fCO2_to_pCO2(380, 8) #381.50806486"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is not required in this set of code but preserving for other use\n",
    "def pCO2_to_fCO2(pCO2SW_uatm, tempSW_C, pres_hPa=None, tempEQ_C=None):\n",
    "    \"\"\"\n",
    "    Convert fCO2 to pCO2 for SOCAT in sea water. A simple version of the\n",
    "    equation would simply be:\n",
    "        fCO2sw = pCO2sw / virial_exp\n",
    "    where the virial expansion is calculated without xCO2\n",
    "    We get a simple approximate for equilibrator xCO2 with:\n",
    "        xCO2eq = pCO2sw * deltaTemp(sw - eq) / press_eq\n",
    "    fCO2sw is then calculated with:\n",
    "        fCO2sw = pCO2sw * virial_exp(xCO2eq)\n",
    "    Parameters\n",
    "    ----------\n",
    "    pCO2SW_uatm : array\n",
    "        seawater fugacity of CO2 in micro atmospheres\n",
    "    tempSW_C : array\n",
    "        sea water temperature in degrees C/K\n",
    "    tempEQ_C : array\n",
    "        equilibrator temperature in degrees C/K\n",
    "    pres_hPa : array\n",
    "        pressure in kilo Pascals\n",
    "    Returns\n",
    "    -------\n",
    "    fCO2SW_uatm : array\n",
    "        partial pressure of CO2 in seawater\n",
    "    Note\n",
    "    ----\n",
    "    In FluxEngine, they account for the change in xCO2. This error is so small\n",
    "    that it is not significant to be concerned about it. Their correction is\n",
    "    more precise, but the difference between their iterative correction and our\n",
    "    approximation is less than 1e-14 atm (or 1e-8 uatm).\n",
    "    Examples\n",
    "    --------\n",
    "    >>> pCO2_to_fCO2(380, 8)\n",
    "    378.49789637942064\n",
    "    >>> pCO2_to_fCO2(380, 8, pres_hPa=985)\n",
    "    378.53967828231225\n",
    "    >>> pCO2_to_fCO2(380, 8, pres_hPa=985, tempEQ_C=14)\n",
    "    378.53960618459695\n",
    "    \"\"\"\n",
    "    #import check_units as check\n",
    "    #import auxiliary_equations as eqs\n",
    "\n",
    "    # if equilibrator inputs are None then make defaults Patm=1, tempEQ=tempSW\n",
    "    if tempEQ_C is None:\n",
    "        tempEQ_C = tempSW_C\n",
    "    if pres_hPa is None:\n",
    "        pres_hPa = 1013.25\n",
    "\n",
    "    # standardise the inputs and convert units\n",
    "    pCO2sw = CO2_mol(pCO2SW_uatm * 1e-6)\n",
    "    Tsw = temp_K(tempSW_C + 273.15)\n",
    "    Teq = temp_K(tempEQ_C + 273.15)\n",
    "    Peq = pres_atm(pres_hPa / 1013.25)\n",
    "\n",
    "    # calculate the CO2 diff due to equilibrator and seawater temperatures\n",
    "    dT = temperature_correction(Tsw, Teq)\n",
    "    # a best estimate of xCO2 - this is an aproximation\n",
    "    # one would have to use pCO2 / Peq to get real xCO2\n",
    "    xCO2eq = pCO2sw * dT / Peq\n",
    "\n",
    "    fCO2sw = pCO2sw * virial_coeff(Tsw, Peq, xCO2eq)\n",
    "    fCO2sw_uatm = fCO2sw * 1e6\n",
    "\n",
    "    return fCO2sw_uatm\n",
    "\n",
    "#pCO2_to_fCO2(380, 8) #378.49789638"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test(y, pred):\n",
    "    \"\"\"\n",
    "    Create metrics for evaluation of a model's predictions\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : numpy array\n",
    "        actual values for a dependent variable\n",
    "    pred : numpy array\n",
    "        predicted values for the dependent variable\n",
    "    Returns\n",
    "    -------\n",
    "    scores : dictionary\n",
    "        a dictionary of 13 metrics \n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import r2_score, max_error, mean_squared_error, mean_absolute_error, median_absolute_error\n",
    "    \n",
    "    y_mean = np.mean(y)\n",
    "    pred_mean = np.mean(pred)\n",
    "    centered_rmse = np.sqrt(np.square((pred - pred_mean) - (y - y_mean)).sum()/pred.size)\n",
    "\n",
    "    scores = {\n",
    "        'mse':mean_squared_error(y, pred),\n",
    "        'mae':mean_absolute_error(y, pred),\n",
    "        'medae':median_absolute_error(y, pred),\n",
    "        'max_error':max_error(y, pred),\n",
    "        'bias':pred.mean() - y.mean(),\n",
    "        'r2':r2_score(y, pred),\n",
    "        'corr':np.corrcoef(y,pred)[0,1],\n",
    "        'cent_rmse':centered_rmse,\n",
    "        'stdev' :np.std(pred),\n",
    "        'amp_ratio':(np.max(pred)-np.min(pred))/(np.max(y)-np.min(y)), # added when doing temporal decomposition\n",
    "        'stdev_ref':np.std(y),\n",
    "        'range_ref':np.max(y)-np.min(y),\n",
    "        'iqr_ref':np.subtract(*np.percentile(y, [75, 25]))\n",
    "        }\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is useful to format the output from evaluate_test()\n",
    "def print_dict_as_table(seq, columns=4):\n",
    "    \"\"\"\n",
    "    Prints a dictionary formatted as a table\n",
    "    Parameters\n",
    "    ----------\n",
    "    seq : dictionary\n",
    "        a dictionary to print\n",
    "    columns : int\n",
    "        number of columns to print\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    table = ''\n",
    "    col_height = (len(seq) // columns) +1\n",
    "    for x in range(col_height):\n",
    "        for col in range(columns):\n",
    "            if x + (col_height * col) <= len(seq)-1:\n",
    "                a = list(seq.keys())[x + (col_height * col)]\n",
    "                b = seq[list(seq.keys())[x + (col_height * col)]]\n",
    "                num = '{:.9s}: {:.3f}'.format(a + ' '*20, round(b,3))\n",
    "            else:\n",
    "                num = ''\n",
    "            table += ('%s' % (num)).ljust(24)\n",
    "        table += '\\n'\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Functions\n",
    "\n",
    "TBD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leap_test202308-2",
   "language": "python",
   "name": "leap_test202308-2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
